Drivers are 2.6.12, except esp-2.5.62.

The current table 1
-------------------
		KLOC	Time	Warn	Ungrd	Races (if different)
aget		1.6	1s	15	15
knot		1.7	1s	11	8
ctrace		1.8	1s	8	8	2
pfscan		1.7	0.6s	6	0
engine		1.5	1s	7	0
smtprc		6.1	5.8s	46	1* 
freshclam	54	(did not finish)

esp    		9.3	46s	27      1*	1
plip		19.5	17s	15	6
synclink	25	18.8m	90	1*
consolemap	9.5	1s	4	0*
serial-core	15.2		7	0*
ide-disk	18.9	36s	5	0*

*still examining the output

Note that all decision of races in drivers assumes we got main()
right.  Also we ignore a spurious race in our main() itself in
plip.

The submitted table 1
-------------------
		KLOC	Time	Warn	Ungrd	Races (if different)
aget		1.6	1s	7	2	2
knot		1.4	1s	8	8	8
ctrace		1.4	1s	3	3	1
freshclam	55	51m	11	0	

esp    		9.3	46s	19      1
plip		19.5	17s	1	0
synclink	25	18.8m	2	0
consolemap	9.5	1s	1	0
serial-core	15.2		0	0
ide-disk	18.9	36s	0	0

IDE-DISK
========

(Seems to be due to the 2.6 kernel.)

Notes: no sync in this driver!

When I call ide_register_driver, it sticks the driver in some
list.  Then it attaches the driver to the bus by calling drvier_attach
(bus.c), which finds a device object to associate with the driver,
which ultimately calls driver_probe_device (bus.c) which calls back to
the driver.gen_driver's probe function.  Assuming this returns 0, the
dev->driver field is set to the driver struct, and it will call
device_bind_driver (bus.c) which sets some other fields in the driver.

PLIP
====
(tool version from 3/8)

I added a better main() that should exercise most functionality, but I
might have gotten the kernel conventions wrong, and there may still be
some routines that aren't reached, but hopefully not.

Total warnings    Guarded-by violations    False alarms
17                                         1

False alarms:

(1) .hard_start_xmit#24621\nplip_comb.c:15956
(2) .open#24620\nplip_comb.c:15956
(3) .stop#24619\nplip_comb.c:15956
(4) .get_stats#24618\nplip_comb.c:15956
(5) .do_ioctl#24617\nplip_comb.c:15956
(6) .header_cache_update#24616\nplip_comb.c:15956
(7) .tx_queue_len#24615\nplip_comb.c:15956
(8) .flags#24614\nplip_comb.c:15956
(9) .hard_header#24613\nplip_comb.c:15956
(10) .hard_header_cache#24612\nplip_comb.c:15956

At this point the data is thread local, so even though the device is
ultimately assigned to a global variable, it shouldn't be considered a
race.

Also, at 17164 there is a use of memset to set a field.  It should be
giving us the same false alarm; because it isn't I'm presuming we are
not handling this particular memset properly.

(11) .trans_start#24609\nplip_comb.c:15956

I don't know whether this is a false alarm or not; however just before
the line of the first deref (17385), there is a
_spin_lock_irq(&nl->lock) but the tool is not aware of it (it doesn't
indicate that any lock is acquired).  At first, the netdev_priv()
function was being stupid so I changed it to return the dev->priv
field, which is declared as a void* but is really a struct net_local
containing a lock.  Aha---perhaps this is where I need an existential!

(12) .irq#37914\nplip_comb.c:15958

Possible race?  It seems that dev->irq is accessed willy-nilly without
any locks held.  For example, in plip_receive_packet, it's accessed as
almost the first thing in the function, even before disable_irq is
called (which might potentially provide synchronization).

(13) .base_addr#37913\nplip_comb.c:15958

False positive.  All accesses in plip_attach, and calls to that are
guarded by registration_lock.

(14) .state#37910\nplip_comb.c:15958

These may be false positives.  All the accesses are happening in
inlined assembly code---&dev->state is passed to test_and_set_bit,
test_and_clear_bit,  constant_test_bit, variable_test_bit, clear_bit,
and set_bit.   These calls are all in functions that begin with netif_
or __netif_.  These functions are called with no locks held in
plip_tx_packet.  However, I don't know if there are special
characteristics of the assembly code that make these safe.

(15) .next_sched#37909\nplip_comb.c:15958

False positive?  This is set in __netif_schedule and never read.  It's
called by netif_wake_queue, which is called by netif_device_attach
(never called), by plip_connection_close with &nl->lock held, and in
plip_error with no lock held, and in plip_interrupt with &nl->lock
held.  Not sure what's happening here.

(16) &dummydev#9738\nplip_comb.c:18283

Ignore--this is a race in our code, due to the way we set it up.

(17) &unit#9027\nplip_comb.c:18100

False positive.  This is a global variable (static) that's only ever
accessed in plip_attach, and plip_attach is only called with
registration_lock held.  Hence there shouldn't be a race.

PLIP KO_MERGED
==============

Total warnings
20

(*) means nothing here (just makes it easier to spot the lines)

(*) &dummydev#7383\nplip.ko_merged.c:19044

Ignore--this is a race in our code, due to the way we set it up.

(*) .connection#26059\nplip.ko_merged.c:19069
(*) .is_deferred#26048\nplip.ko_merged.c:19069
(*) .nibble#26053\nplip.ko_merged.c:19069
(*) .pardev#26056\nplip.ko_merged.c:19069
(*) .port_owner#26057\nplip.ko_merged.c:19069
(*) .should_relinquish#26062\nplip.ko_merged.c:19069
(*) .timeout_count#26064\nplip.ko_merged.c:19069
(*) .trigger#26065\nplip.ko_merged.c:19069

This are all fields of struct net_local.  It appears that the driver
assumes that this structure is thread local, since all of these fields
are accessed without locks held.  Our model is that this structure is
actually shared.  If that's really true, there are a bunch of races.

connection -- Race?  Accessed in plip_bh with no lock held, and written in
plip_receive_packet.

is_deferred -- Race?  Written in plip_bh and read in plip_kick_bh, no locks.

nibble -- Race?  Read and written in plip_ioctl with no locks

pardev -- False positive.  Write to a field of a thread-local data
structure that has just been allocated as part of alloc_etherdev
above.

port_owner -- Race? Written in plip_connection_close with no lock
held.

should_relinquish -- Race? Written in plip_open with no lock held.

timeout_count -- False positive (EXISTS).  Guarded by &nl->lock.  Hm,
this suggests that this structure is actually shared, or it's a
coincidence that a lock is held when accessing this.  It's unclear,
though, because it's not accessed alone (there's always another field
of nl being accessed at the same time).

trigger -- Race?  Written in plip_ioctl with no locks

(*) .dev#26047\nplip.ko_merged.c:19094 (UNIQUENESS, THREAD-LOCAL MALLOC)
(*) .protocol#18106\nplip.ko_merged.c:19094 (DEEPER UNIQUENESS, AND/OR MALLOC WRAPPER)

False positive.  rcv->skb is allocated fresh above this on line 17929, and hence
is thread local.  It's getting confused with another sk_buff returned by
dev_alloc_skb().

False positive.  An sk_buff is allocated in xmit_packet(), and there's
a comment next to the allocation saying that it's thread local (from
Mike).  Then the dev field is initialized, and it's passed to
plip_tx_packet, which then accesses the dev field as well.  If
uniqueness is fixed, this warning should go away.

However, this is still a little suspicious.  The sk_buff is stored in
another struct, and eventually it looks like schedule_work() is passed
the struct, which presumably does the actual work of accessing the
buffer.  We don't have code for schedule_work() in the file.  So this
makes me wonder if we had that code whether we'd decide there was a
problem, i.e., there might be a thread handoff here.

It's the same both for the dev and protocol fields

(*) .last_rx#18121\nplip.ko_merged.c:19068
(*) .next_sched#18123\nplip.ko_merged.c:19068
(*) .priv#18126\nplip.ko_merged.c:19068
(*) .trans_start#18135\nplip.ko_merged.c:19068
(*) .state#17987\nplip.ko_merged.c:19068

There used to be warnings about all of the fields of this structure.
Now there are only warnings about these fields.

last_rx seems to be a RACE.  It's written in plip_receive_packet with
no lock held.

next_sched is written with no locks held---but interrupts have been
cleared, and it might be that in this context that makes it safe.

priv is a false positive.  This field is only set during
initialization time, and then it's just read.  The data in the field,
however, is accessed in various ways.

trans_start is accessed with a lock held, but it's nl->lock, which our
analysis says is non-linear.  Hence this is a false positive that can
be addressed with (EXISTS).

state is accessed with no lock held in various places.  But it seems
to be accesed by some assembly code, so suspect that these accesses
are safe.


False positives eliminated by fix for context-sensitive locking

(*) &unit#6631\nplip.ko_merged.c:18631
(*) .base_addr#18157\nplip.ko_merged.c:19068

False positive.  This is a global variable (static) that's only ever
accessed in plip_attach, and plip_attach is only called with
registration_lock held.  Hence there shouldn't be a race.

False positives eliminated by new uniqueness?

(*) .do_ioctl#18160\nplip.ko_merged.c:19068 (INIT FUNCTION, EXTENDED UNIQUENESS)
(*) .flags#18139\nplip.ko_merged.c:19068
(*) .get_stats#18140\nplip.ko_merged.c:19068
(*) .hard_header#18142\nplip.ko_merged.c:19068
(*) .hard_header_cache#18141\nplip.ko_merged.c:19068
(*) .hard_start_xmit#18144\nplip.ko_merged.c:19068
(*) .header_cache_update#18143\nplip.ko_merged.c:19068
(*) .open#18125\nplip.ko_merged.c:19068
(*) .stop#18131\nplip.ko_merged.c:19068
(*) .tx_queue_len#18134\nplip.ko_merged.c:19068

This data is initialized in plip_init_netdev, which is called
thread-locally after the device is allocated by alloc_etherdev.  To
catch this case we would need to realize that thread-local data is
being written.

(*) .irq#18147\nplip.ko_merged.c:19068 [no longer reported?]

Race?  Assuming that dummydev is really shared by everyone, this field
is accessed with no locks held in various places.

Removed by some change to the code...?

Actually, this seems to be only read after it's set in plip_attach as
a thread-local initialization, so it probably was a false positive.


AGET
====
(tool version from 3/3, updated 3/12, updated 3/15)

Summary:
Total warnings    Guarded-by violations    False alarms
15                9                        4

Off the top of my head, I'd say all of these races are genuine,
but benign.  Here's the breakdown, where the order next to the race
is the order it appears in the output file.

(10) &bwritten#3831\naget_comb_lib.c:943

RACE! This is a read/write race.  The variable is read without protection
when updating the status bar; presumably the race is benign because
it doesn't matter if it's exactly correct.  But this is not going
to work witout -sequential consistency.

(11) &prev#3007\naget_comb_lib.c:779

RACE! Similar to the above.  Basically the prev variable could be accessed
from either the sigalrm handler in the signal thread or from the
worker threads; the variable is accessed in the updateProgressBar
routine.

&nthreads#304\naget_comb.c:172

RACE!  The signal handler thread is forked before this variable is
initialized.  If a signal is received before nthreads and wthread have been
initialized, the signal-handler thread might read this variable while it's still
uninitialized.  It then uses it as an index in wthreads[].  This could cause
a segfault.

(*) .clength#5662\naget_comb.c:435
(*) .clength#5671\naget_comb.c:335
(*) .fd#5658\naget_comb.c:435
(*) .fd#5667\naget_comb.c:335
(*) .foffset#5659\naget_comb.c:435
(*) .foffset#5668\naget_comb.c:335
(*) .offset#5661\naget_comb.c:435
(*) .offset#5670\naget_comb.c:335
(*) .soffset#5656\naget_comb.c:435
(*) .soffset#5665\naget_comb.c:335
(*) .status#5654\naget_comb.c:435
(*) .status#5663\naget_comb.c:335

In short: real race(s) on a global shared data structure, but unlikely
to happen in practice.  However, I don't think that locksmith actually
figured this out, because the race occurs due to a memcpy on a struct,
and I'm not sure that it handles that?  Otherwise, it would have
printed races on other fields too, I think.

wthread is a global array that is allocated at this spot in get().
The get() function is called from main() in the main thread, and
wthread is used here, and in the functions resume_get() and
save_log().  The former function is also called from main().

The race occurs, I believe, due to the call to save_log from
sigint_handler.  The program is set up to block signals from all
threads other than the signal_waiter thread.  This thread waits for a
SIGINT, and if it gets it, it calls save_log.  save_log writes wthread
out to disk, reading it without synchronization.  However, the main
thread might be writing wthread at the same time, e.g., when it is
initialized in get() or resume_get().  Therefore, the value saved to
disk could be corrupted.  This would only happen at startup, since
wthread is not modified once it is initialized.

The draft of the paper points out that each element of the wthread
array is thread local data, so that accesses to the array from within
each thread might appear to be races, but in fact are accessing
distinct storage. This is true, but the race noted here still exists.

A similar thing happens with the req structure (the last in this
list).  We also have a sort of read/write race on the req->clength
field accessed in the sigalrm_handler and potentially from 
the main thread.  But even if it were to happen, it would only
be as the whole process is finishing, so it should be considered
benign.

QUESTION: why is req considered the source of a data race, but
its individual fields are not?

False alarms:

(1) struct hist_data h (line 187, in main()) .req field
      now reported on line 
(8) struct hist_data h (line 1136, in save_log()) .req field

In short: is thread-local, but somehow is inferred as being
thread-shared.  Not sure why, since it seems to only appear in
the main thread.

The hist_data struct contains information about the download if it was
interrupted.  At the start of the program, main() initializes this
structure by reading in an on-disk log file, if present.  So the
argument to read_log(hist_data *) is initialized there with fread.
This is then passed to resume_get(hist_data *) and is therein used to
seed the recreation of a bunch of threads, but is never passed to
these threads.  The same data structure is declared as a local
variable in save_log.

QUESTION: I don't understand the references output.  The rho stuff
does not appear to be a true path, and elements in it are repeated.
Moreover, the whole group of guard@aget_comb_lib.c:218 appears twice;
as in other cases.  Also, the dereference sites seems; presumably due
to conservative aliasing.  For example, the deref on line 218 is for
the global req variable which is never an alias for this field.  How
is this happening?  Also, the list of accesses includes line 1136,
which is a different allocation site for a variable with the same
name. 

(12) Possible data race: alloc#3552\naget_comb_lib.c:775

This is false sharing, as with rbuf above.
[not sure what this is...isn't in current version; probably a false
 positive eliminated by down fork]


Possible races:

(2) struct thread_data *wthread (line 346, in get()) .soffset field
(*) .foffset#7652\naget_comb.c:335 
(.) .fd#6084\naget_comb.c:335
(.) .foffset#6076\naget_comb.c:435
(.) .foffset#6085\naget_comb.c:335
(.) .offset#6087\naget_comb.c:335
(3) struct thread_data *wthread (line 346, in get()) .status field
(4) struct thread_data *wthread (line 346, in get()) .offset field
(5) struct thread_data *wthread (line 451, in resume_get()) .soffset field
(*) .foffset#7643\naget_comb.c:435 
(.) .fd#6075\naget_comb.c:435
(.) .foffset#6076\naget_comb.c:435
(.) .offset#6078\naget_comb.c:435
(6) struct thread_data *wthread (line 451, in resume_get()) .status field
(7) struct thread_data *wthread (line 451, in resume_get()) .offset field
(13) alloc#381\naget_comb.c:188
[was alloc#396\naget_comb_lib.c:193]

NOTE: the (*) cases got added by the 3/11 fix.  They are legitimate.
NOTE: the (.) cases got added on 3/15

[moved above]

False postive hidden by applying down at fork:

(*) alloc#3640\naget_comb.c:760

Allocation of purely thread-local buffer for error logging.  Correct to hide this.

(*) alloc#5270\naget_comb.c:1022
[was (9) char *rbuf (line 1042 in http_get)]

In short: seems to be mistakenly thinking that it's shared, but
instead rbuf is allocated within each thread separately.  I was able
to reproduce this problem myself in a smaller program.  I would
assume that sometimes the uniqueness analysis handles this case,
but perhaps not here because it's passed to another function.
-- solved by applying down 

rbuf in httpd_get.  false sharing eliminated


KNOT
====

alloc.refs (knot_comb.c:319)
  claim is that it's protected by a non-linear lock.  I can't make any
  sense of the warning message, so I don't know if this is a possible
  race we missed before or if it's bogus.  Given the gobbledygook of
  the error message, I'm suspicious that this is some kind of bug.

&attr_init_done#4035\nknot_comb.c:1018.  (RACE!)

  This is a global static variable.  It's accessed in accept_loop,
  which might be called by different threads, without a lock.  Note
  that this is arguably benign, since it's written once.  The issue
  could be the race on the check and write, meaning that the if block
  could run twice.  They really want to be doing some kind of
  double-checked locking here.

&g_bytes_sent#2855\nknot_comb.c:735.  RACE!

  Global variable accessed with no lock in process_client_nocache,
  which might be called by different threads, without a lock.

&g_cache_hits#460\nknot_comb.c:260 
&g_cache_misses#461\nknot_comb.c:261

  RACES!  These counters are accessed both within the cache code
  (thread-locally) and in main, in a routine that gather statistics.

&g_conn_active#2854\nknot_comb.c:732.  RACE!

  Global variable accessed with no lock in thread_process_client,
  which might be its own thread.

&g_conn_fail#2852\nknot_comb.c:730.  RACE!

  Global variable accessed with no lock in process_client, which may
  be called by different threads.

&g_conn_open#2851\nknot_comb.c:729.  RACE!  

  Global variable accessed with no lock in accept_loop, which may be
  called by different threads.

&g_conn_succeed#2853\nknot_comb.c:731.  RACE!

  Global variable accessed with no lock in process_client, which may
  be called by different threads. 

alloc#3910\nknot_comb_annot.c:1222 (THREAD-LOCAL: UNIQUE/LIVE)
.id#9507\nknot_comb.c:1189 
.s#9506\nknot_comb.c:1189

  False positives; this is a field of an argument massed in to a
  newly created thread within a loop:

    while (i < nthreads) {
      targs = (thread_args *)malloc(sizeof((*targs)));
      targs->id = i;
      targs->s = s;
      pthread_create(..., targs));
    }

  Would need to combine liveness with uniqueness to fix

Note that with uniqueness turned off, we get races on the 6 fields of
cache_entry:  .data, .filename, .next, .prev, .refs, .total.  This
races are suppressed by uniqueness because uniqueness knows that the
cache_entry is thread-local, even though its rho is reachable globally
because it will eventually be stored in a global variable.


----------------------------------------------------------------------

The following 6 are due to the plhash.c file which is no longer merged
in with knot.

.key#8089\nknot_comb_annot.c:1334  (CACHING LOGIC?)
.keyHash#8090\nknot_comb_annot.c:1334
.next#8091\nknot_comb_annot.c:1334
.value#8088\nknot_comb_annot.c:1334
alloc#4215\nknot_comb_annot.c:1320
alloc#4258\nknot_comb_annot.c:1334

  These can be indeed accessed by multiple threads simultaneously, but
  they will always be read/read accesses since a cache entry doesn't
  change once created, other than its refs field, which is protected
  by the refs mutex.

  But...even if we fixed that problem, it won't help.  The cache
  entry gets destroyed at line 502 by calling free(entry).  This
  happens *without* the lock held.  But at this point there are no
  more references to the cache entry, so it's safe to destroy it.
  This seems hard to fix...

  It looks like all the fields of cache_entry are getting conflated.
  The reason they're getting conflated is because the hash table and
  the buckets are getting passed to allocOps->freeTable, and the buckets
  contain pointers to cache_entry.

  Note:  the .total field doesn't list the write at the call to
  free().  Seems to be a bug in the guarded-by listings?

  
CTRACE
====

(1), (2), (3), (4), (5) tthread_t.next, .id, .level, .on, plus alloc
itself.  These fields are guarded by a semaphore.  False positive.

	* These fields are accessed with no sempahores in trc_end() after
	  all threads have been joined with pthread_join.  This is
	  safe, but not modeled by Locksmith.
	* Sometimes the semaphore is not acquired.  There's a check
	  if (!_hashreads) { sem_wait(&_hashsem);} and similarly at
	  the release. (e.g., trc_trace)

(6) &_hashreads.  This is a global variable, and accesses to it are
    always guarded by _hashmutex, which somehow is being marked as
    non-linear.  It's not clear why.  This seems to be a BUG.
    trc_init creates _hashmutex, and trc_init is called directly from
    main.

    MORE: seems to have to do with lockset propagation.  sem_wait() is
    called sometimes when a lock is held and sometimes when it is
    released.  This seems to confuse things.

    FIXED: this is now reported as protected by _hashmutex.

(7) &_numthreads.  Global variable.  False positive, protected by a semaphore.

(8) &_msgs.  Global variable.  RACE!  Accessed in trc_trace with
    semaphore held but no lock.  trc_trace is invoked in thread1,
    which is crated in main.  Also accessed in  trc_start_server,
    which is a thread created by trc_init, which is also called from
    main.

(9) &_server. Global variable.  RACE!  This is a flag used to tell a
    server thread to stop running.  It is set in main() but could be
    simultaneously read by the server thread (by design!).
  
CONSOLEMAP
====
(tool version from 3/7)

NOTES

We may be misleading in the paper: the actual lines of code in the
driver itself, including comments, is 684.  Everything else is the
myriad of prototypes and everything else that we won't end up
processing.  

Moreover, this appears to be just part of the actual driver which is
not itself a module; according to the Makefile:

obj-$(CONFIG_VT) += vt.o vc_screen.o consolemap.o consolemap_deftbl.o
$(CONSOLE) selection.o
 
(where $(CONSOLE) is console.o)

It appears on a quick glance that consolemap_init() may not be called
from a separate thread, but rather at start time.



Total warnings    Guarded-by violations    False alarms
4                 1                        3

(1) &__pus_tmp___1#4324\nconsolemap_comb.c:9455
(2) &__pus_tmp___0#4321\nconsolemap_comb.c:9449
(3) &__pus_tmp#4320\nconsolemap_comb.c:9448

False positives.  These are all local variables in con_get_unimap
whose address is taken.  (It's hard to see, but these really are three
different variables; they're being renamed by CIL from their original
names.)  This appears to be the standard & false positive, because
they're clearly thread-local no matter what.

(4) &dflt#986\nconsolemap_comb.c:9123

This is a global variable accessed in con_release_unimap,
con_clear_unimap, con_set_unimap, and con_set_default_unimap.  These
functions all call each other, and con_free_unimap and
con_unify_unimap also call con_release_unimap.  con_copy_unimap also
calls con_free_unimap.

The reason there's a race.
  * con_set_default_unimap is called in console_map_init.  This should
    not be contributing to the race, I hope.
  * con_free_unimap and con_copy_unimap are called by separate threads
    in the driver, hence there's a race.  If this driver is correct,
    then this is a correct warning about the race.

KNOT_OLD
====
(tool version from 3/9)

(1) .prev#5385\nknot_comb_old.c:281
(2) .next#5384\nknot_comb_old.c:281
  Both of these are part of the cache_entry data structure.  So this
  is the same false positive.  However, it's unclear why these are
  not reported for the new version of knot.

(3) .refs#5382\nknot_comb_old.c:281
  [new: False positive]
(4) .total#5381\nknot_comb_old.c:281
(5) .data#5380\nknot_comb_old.c:281
(6) .socket#5378\nknot_comb_old.c:509
  [new: False positive]
(7) .valid#5376\nknot_comb_old.c:509
  [new: False positive]
(8) .used#5375\nknot_comb_old.c:509
  [new: False positive]
(9) .closed#5374\nknot_comb_old.c:956
  [new: False positive]
(10) .version#5373\nknot_comb_old.c:956
  [new: False positive]
(11) .socket#5372\nknot_comb_old.c:956
  [new: False positive]
(12) .id#5367\nknot_comb_old.c:1194
  [new: False positive]
(13) .s#5366\nknot_comb_old.c:1194
  [new: False positive]
(14) &optval#4080\nknot_comb_old.c:1026
  [new: False positive]
(15) &len#4079\nknot_comb_old.c:1024
  [new: False positive]
(16) &attr_init_done#4064\nknot_comb_old.c:1019
  [new: RACE]
(17) alloc#3576\nknot_comb_old.c:907
(18) &g_bytes_sent#2884\nknot_comb_old.c:728
  [new: RACE]
(19) &g_conn_active#2883\nknot_comb_old.c:725
  [new: RACE]
(20) &g_conn_succeed#2882\nknot_comb_old.c:724
  [new: RACE]
(21) &g_conn_fail#2881\nknot_comb_old.c:723
  [new: RACE]
(22) &g_conn_open#2880\nknot_comb_old.c:722
  [new: RACE]

(23) &g_cache_cur#480\nknot_comb_old.c:229
(24) &g_cache_tail#475\nknot_comb_old.c:227
(25) &g_cache#469\nknot_comb_old.c:226
(26) &g_cache_misses#460\nknot_comb_old.c:224
(27) &g_cache_hits#459\nknot_comb_old.c:223

SMTPRC
======

46 warnings
1 race
  -- the very first one.  The cleaner thread every once in a while
decrements o.cur_threads without holding a lock.  The same variable is
accessed elsewhere.

1 potential race
  -- the cleaner every once in a while walks through the set of
running threads and then joins with one, and overwrites its thread_id
in an array.  In theory there could be a race, because o.cur_threads
is decremented before the thread value is nulled out, so even if the
access to o.cur_threads was properly synchornized, this wouldn't help.
However, the program logic seems busted, because it seems that sports
in the thread array aren't reused.

The other 44 warnings are false positives, in my opinion, though it's
hard to be 100% sure.  These seem to be thread-local data stored in a
shared array, but each thread only accesses its part of the array.

.cur_threads#20640\nsmtprc_comb.c:220  RACE!

  Accessed from: main() -> start_scan()
                 main() -> start_scan() FORKS cleaner_start()

  Programmer's assumption seems to be that timing of thread lifetimes
  will avoid possible races?

  RACE: .cur_threads is written to in 
                 main() -> start_scan() FORKS cleaner_start() (multiple threads)
                 main() -> start_scan() (W/W race)

(*) .error_code#20613\nsmtprc_comb.c:2429
(*) .failed#20615\nsmtprc_comb.c:2429
(*) .fatal#20631\nsmtprc_comb.c:1046
(*) .fatal_error#20632\nsmtprc_comb.c:1046
(*) .passed#20617\nsmtprc_comb.c:2429
(*) .resolved#20636\nsmtprc_comb.c:1046
(*) .smtp_open#20630\nsmtprc_comb.c:1046

False positives.  Field of a shared array of what appears to be
thread-local data, hence writing this field is safe.  (I'm assuming
this if cur_host is added on before indexing.)  Accessed in main(),
but only after threads have finished.

(*) alloc#15810\nsmtprc_comb.c:4559
(*) alloc#15861\nsmtprc_comb.c:4574
(*) alloc#15914\nsmtprc_comb.c:4590
(*) alloc#15961\nsmtprc_comb.c:4603
(*) alloc#16053\nsmtprc_comb.c:4643
(*) alloc#16172\nsmtprc_comb.c:4674
(*) alloc#16223\nsmtprc_comb.c:4689
(*) alloc#16270\nsmtprc_comb.c:4702

These are all aliases of each other.  Seem to be false
positives---malloc'd memory stored in this thread-local data.

(*) alloc#16366\nsmtprc_comb.c:4752

Same issue as above, but not an alias.

(*) alloc#16502\nsmtprc_comb.c:4784
(*) alloc#16586\nsmtprc_comb.c:4813
(*) alloc#16637\nsmtprc_comb.c:4830
(*) alloc#16690\nsmtprc_comb.c:4849
(*) alloc#16745\nsmtprc_comb.c:4867

Same issue as above, but another set of aliases

(*) alloc#16841\nsmtprc_comb.c:4926

Same issue as above, but not an alias

(*) alloc#16997\nsmtprc_comb.c:4960
(*) alloc#17123\nsmtprc_comb.c:5000
(*) alloc#17174\nsmtprc_comb.c:5017
(*) alloc#17227\nsmtprc_comb.c:5036
(*) alloc#17282\nsmtprc_comb.c:5056
(*) alloc#17361\nsmtprc_comb.c:5091

Same issue as above, another set of aliases

(*) alloc#17544\nsmtprc_comb.c:5158
(*) alloc#17628\nsmtprc_comb.c:5187
(*) alloc#17679\nsmtprc_comb.c:5204
(*) alloc#17732\nsmtprc_comb.c:5223
(*) alloc#17787\nsmtprc_comb.c:5241

Another set of aliases

(*) alloc#18028\nsmtprc_comb.c:5338
(*) alloc#18079\nsmtprc_comb.c:5355
(*) alloc#18132\nsmtprc_comb.c:5374
(*) alloc#18187\nsmtprc_comb.c:5394
(*) alloc#18260\nsmtprc_comb.c:5426
(*) alloc#18319\nsmtprc_comb.c:5446

Another set

(*) alloc#18485\nsmtprc_comb.c:5503
(*) alloc#18530\nsmtprc_comb.c:5515

Another set

(*) alloc#18685\nsmtprc_comb.c:5565
(*) alloc#18730\nsmtprc_comb.c:5576

Another set

(*) alloc#7304\nsmtprc_comb.c:2291

This should be a race.  An array of thread id's.  After
initialization, each one is written by the individual thread.  Then
the cleaner thread comes along every once in a while and joins a
thread.  But it will only write over the thread's part of the array
after that thread is dead.  However, there could be another thread
created that uses the same part of the array---except that seems to be
forbidden by the program logic.

(*) alloc#7780\nsmtprc_comb.c:2412

False positive for the same reason as all the other aliases above.

PFSCAN
======

(*) &aworkers#573\npfscan_comb.c:215  (FLOW-SENS THREAD LOCAL)
  This is a variable that is properly protected by a mutex when it is
  shared; it is initialized in main() prior to forking threads, so
  that this access is unprotected.  There is an access in main() and
  two other threads after the main() fork.  Flow-sensitive sharing
  will catch this.

(*) &n_matches#581\npfscan_comb.c:221 (THREAD LOCAL POST JOIN)
  This is a shared variable properly synchronized; the apparent race
  occurs at the end of main() where it is accessed without a lock.
  But the use of a condition variable ensures that all worker threads
  have completed so the access is safe.

(*) .closed#6918\npfscan_comb.c:225 (FLOW-SENS THREAD LOCAL)
  Written to in the pqueue_init function, and then always protected by
  a lock.  Flow-sensitive sharing should catch this.

(*) .nextout#6915\npfscan_comb.c:225 (THREAD LOCAL UNIQUE; BUG?)
  Same deal as above, except that also it thinks that a lock isn't
  held on line 1265, but clearly it is.

(*) .occupied#6916\npfscan_comb.c:225 (THREAD LOCAL UNIQUE; BUG?)
  Same as above, but same problem too; e.g. no lock reported held on
  line 1230.

  Why are not the other fields of the PQUEUE struct also not reported
  in the same way?  The ones accessed in initialization are
  qsize, nextin, buf.

  .nextin isn't a race becausaes it's only access in the main thread.
  .qsize is only read

  .buf is only accessed with lock qp->mtx held.  Seems like we would
  think this lock is non-linear, though.

  ** should be solvable with (EXISTS) once we generate the warning
 
(*) alloc#6018\nlib.c:152 

  Spurious alarm from strdup().  Should really fix this by making
  strdup like an allocation function.

ENGINE
======

&duplicount#511\nengine.c:110
&resltcount#512\nengine.c:111
&totalcount#510\nengine.c:109

False positives.  The counters are protected when accessed by the forked
threads, and only accessed by main after all threads have been joined.

.dupcount#5969\nengine.c:968
.dupcount#5995\nengine.c:257

These are false positives, because this field is only accessed without
a lock in main without a lock held, and because of same reason below...

.lnkcount#5947\nengine.c:968
.lnkcount#5973\nengine.c:257 

False positive.  The lnkcount field is accessed in a thread without a
lock, but it seems that this is ok.  The field is from a struct that's
an element of a shared list---but each list element is itself
thread-local after being initialized in main.

(*) .sin_addr#8419\nengine.c:798

Seems like a false positive.  There's no sin_addr on line 798, but
there is a sin_addr field of struct sockaddr_in sa on line 795.
That's a local data structure, and it's only modified within this
function thread-locally.  Not sure why it's global.

This seems to have something to do with conflation.  Line 842 is

	memcpy(&sa.sin_addr, hp->h_addr, sizeof(struct in_addr));

If we replace this line with the equivalent

	sa.sin_addr.s_addr = hp->h_addr.s_addr;

then the race goes away.  However, I'm baffled by what's going on,
because looking in engine_lib.c, the memcpy line seems to be turned in
to

	  __asm__  ("booo_exp(engine.c:843)");

which just makes me go---huh?  Especially because hp->h_addr seems ill-formed

ESP
===

refers to the output of esp-2.5.62.c

&dma_bytes#3194\nesp-2.5.62.c:7119
  could be a race.
  accessed from within esp_open -> startup -> rs_interrupt_single ->
    receive_chars_dma_done -> receive_chars_dma
  according to Paul Fulghum (synclink author) calls to tty drivers
  can only run one-instance-at-a-time.  they can only context-switch
  to another instance at points where they sleep.
  Then two context-switching threads calling open() could create a 
  read-write race in receive_chars_dma:
    Thread 1 sets dma_bytes, and blocks on the dma lock.
    Thread 2 is context switched and sets dma_bytes too, then blocks
    on dma_lock as well.
  the problem is this is an atomicity violation, not an empty
  guarded-by, and even modelling a global lock being
  released/reacquired by the blocking call, we shouldn't catch it.

  in our model of main() it's a race.

&tmp_buf#3241\nesp-2.5.62.c:7132
  RACE!
  for our main() this is definitely a race.
  Based on the synclink author comments, this could leak memory:
  offending code in esp_open:
    if (!tmp_buf) {
      tmp_buf = (unsigned char *) get_zeroed_page((0x10 | 0x40 | 0x80));
      if (!tmp_buf)
        return -12;
    }
  two calls to open() could be running at the same time.  Even with the
  kernel holding a global lock for all non-blocking code, they could be
  context switched at the get_zeroed_page() call.  Scenario:
  Thread 1 tests tmp_buf and finds it NULL, so enters the "then" block.
  the call to get_zeroed_page sleeps, causing the global tty lock to be
  released until it's re-awaken.
  Then thread 2 can be context-switched, also test for tmp_buf==0 and try
  to allocate a page.  After that, one of the two pages is never freed.
    The same code in synclink allocates a page into another local variable,
  and re-tests tmp_buf for null after the get_zeroed_page() call, in order
  to free the allocated page if another thread has assigned to tmp_buf.

.blocked_open#34922\nesp-2.5.62.c:8822
.blocked_open#34958\nesp-2.5.62.c:8765
For our main() these are races (the same race on two mallocated locations).
In reality, since tty drivers can only be preempted by another instance of
the driver when blocked, these aren't races because the ++ and -- operations
will be protected by the tty lock.


.closing#34914\nesp-2.5.62.c:8894
false positive.  it's protected by cli_lock.

.count#34930\nesp-2.5.62.c:8822
.count#34966\nesp-2.5.62.c:8765
for our main() it's a race, but really the ++ operation can never be context
switched.

.driver_data#34917\nesp-2.5.62.c:8894
.flags#34909\nesp-2.5.62.c:8894
.flags#34933\nesp-2.5.62.c:8822
.flags#34969\nesp-2.5.62.c:8765
.ignore_status_mask#34936\nesp-2.5.62.c:8822
.ignore_status_mask#34972\nesp-2.5.62.c:8765
.pgrp#34946\nesp-2.5.62.c:8822
.pgrp#34982\nesp-2.5.62.c:8765
.read_status_mask#34947\nesp-2.5.62.c:8822
.read_status_mask#34983\nesp-2.5.62.c:8765
.session#34949\nesp-2.5.62.c:8822
.session#34985\nesp-2.5.62.c:8765
.stat_flags#34948\nesp-2.5.62.c:8822
.stat_flags#34984\nesp-2.5.62.c:8765
.timeout#34950\nesp-2.5.62.c:8822
.timeout#34986\nesp-2.5.62.c:8765
.tty#34953\nesp-2.5.62.c:8822
.tty#34989\nesp-2.5.62.c:8765
.unsafe#35062\nesp-2.5.62.c:4437
.unsafe#35080\nesp-2.5.62.c:4437
same as above, races for our main(), not really races for the real kernel.



old esp comments (refer to esp_comb.c)

(1) &dma#2224\nesp_comb.c:12963

  RACE if main is to be believed.  However, seems to be missing an access in the same function.  The guard from line 15151 is reported,
  but not line 15152.

&dma_buffer#2232\nesp_comb.c:12985
&esp_driver#2243\nesp_comb.c:12996
&flow_off#2227\nesp_comb.c:12966
&flow_on#2228\nesp_comb.c:12967
&free_pio_buf#2235\nesp_comb.c:12987
&ports#2245\nesp_comb.c:12997
&rx_timeout#2229\nesp_comb.c:12968
&rx_trigger#2225\nesp_comb.c:12964
&tmp_buf#2261\nesp_comb.c:13001
&tx_trigger#2226\nesp_comb.c:12965
.IER#19810\nesp_comb.c:15263 (non-lin)
.IER#19843\nesp_comb.c:15195 (non-lin)
.MCR#19817\nesp_comb.c:15263 (non-lin)
.MCR#19850\nesp_comb.c:15195 (non-lin)
.alt_speed#19790\nesp_comb.c:15329 (non-lin)
.blocked_open#19799\nesp_comb.c:15263 (non-lin)
.blocked_open#19832\nesp_comb.c:15195 (non-lin)
.close_delay#19804\nesp_comb.c:15263
.close_delay#19837\nesp_comb.c:15195
.closing_wait#19805\nesp_comb.c:15263
.closing_wait#19838\nesp_comb.c:15195
.count#19806\nesp_comb.c:15263 (non-lin)
.count#19839\nesp_comb.c:15195 (non-lin)
.custom_divisor#19803\nesp_comb.c:15263
.custom_divisor#19836\nesp_comb.c:15195
.data#19878\nesp_comb.c:15195
.data#19883\nesp_comb.c:15263
.data#19888\nesp_comb.c:15195
.data#19893\nesp_comb.c:15263
.driver_data#19792\nesp_comb.c:15329 (non-lin)
.flags#19788\nesp_comb.c:15329 (non-lin)
.flags#19809\nesp_comb.c:15263
.flags#19842\nesp_comb.c:15195
.flow_off#19897\nesp_comb.c:15195
.flow_off#19903\nesp_comb.c:15263
.flow_on#19898\nesp_comb.c:15195
.flow_on#19904\nesp_comb.c:15263
.func#19877\nesp_comb.c:15195
.func#19882\nesp_comb.c:15263
.func#19887\nesp_comb.c:15195
.func#19892\nesp_comb.c:15263
.irq#19813\nesp_comb.c:15263
.irq#19846\nesp_comb.c:15195
.line#19816\nesp_comb.c:15263
.line#19849\nesp_comb.c:15195
.magic#19818\nesp_comb.c:15263
.magic#19851\nesp_comb.c:15195
.next_port#19819\nesp_comb.c:15263
.next_port#19852\nesp_comb.c:15195
.pending#19879\nesp_comb.c:15195
.pending#19884\nesp_comb.c:15263
.pending#19889\nesp_comb.c:15195
.pending#19894\nesp_comb.c:15263
.pio_threshold#19901\nesp_comb.c:15195
.pio_threshold#19907\nesp_comb.c:15263
.port#19821\nesp_comb.c:15263
.port#19854\nesp_comb.c:15195
.rx_timeout#19899\nesp_comb.c:15195
.rx_timeout#19905\nesp_comb.c:15263
.rx_trigger#19900\nesp_comb.c:15195
.rx_trigger#19906\nesp_comb.c:15263
.stat_flags#19823\nesp_comb.c:15263
.stat_flags#19856\nesp_comb.c:15195
.tty#19827\nesp_comb.c:15263 (non-lin)
.tty#19860\nesp_comb.c:15195 (non-lin)
.tx_trigger#19902\nesp_comb.c:15195
.tx_trigger#19908\nesp_comb.c:15263
.xmit_buf#19795\nesp_comb.c:15263 (non-lin)
.xmit_buf#19828\nesp_comb.c:15195 (non-lin)
.xmit_cnt#19798\nesp_comb.c:15263 (non-lin)
.xmit_cnt#19831\nesp_comb.c:15195 (non-lin)
.xmit_head#19797\nesp_comb.c:15263 (non-lin)
.xmit_head#19830\nesp_comb.c:15195 (non-lin)
.xmit_tail#19796\nesp_comb.c:15263 (non-lin)
.xmit_tail#19829\nesp_comb.c:15195 (non-lin)

SYNCLINK
========

59 Warnings

(*) &tmp_buf#2963\nsynclink.ko_merged.c:18463

RACE?  This global variable is accessed and set with no lock held in
mgsl_write.  Assuming that can be called from multiple threads, this
is a race.

 -- not currently a race due to the big kernel lock, but is according
    to our model

(*) .bh_requested#79662\nsynclink.ko_merged.c:22124
(*) .bh_running#79663\nsynclink.ko_merged.c:22124
(*) .blocked_open#79661\nsynclink.ko_merged.c:22124
(*) .buffer_list#79658\nsynclink.ko_merged.c:22124
(*) .buffer_list_phys#79659\nsynclink.ko_merged.c:22124
(*) .cmr_value#79666\nsynclink.ko_merged.c:22124
(*) .count#79668\nsynclink.ko_merged.c:22124
(*) .cts_chkcount#79523\nsynclink.ko_merged.c:22124
(*) .current_rx_buffer#79665\nsynclink.ko_merged.c:22124
(*) .current_tx_buffer#79664\nsynclink.ko_merged.c:22124
(*) .dcd_chkcount#79530\nsynclink.ko_merged.c:22124
(*) .dma_requested#79672\nsynclink.ko_merged.c:22124
(*) .drop_rts_on_tx_done#79673\nsynclink.ko_merged.c:22124 (non-lin)
(*) .dsr_chkcount#79531\nsynclink.ko_merged.c:22124 (non-lin)
(*) .flags#79537\nsynclink.ko_merged.c:22124
(*) .flags#79681\nsynclink.ko_merged.c:22124
(*) .get_tx_holding_index#79682\nsynclink.ko_merged.c:22124
(*) .idle_mode#79554\nsynclink.ko_merged.c:22124
(*) .ignore_status_mask#79551\nsynclink.ko_merged.c:22124
(*) .init_error#79696\nsynclink.ko_merged.c:22124
(*) .intermediate_rxbuffer#79690\nsynclink.ko_merged.c:22124
(*) .io_addr_requested#79689\nsynclink.ko_merged.c:22124
(*) .irq_occurred#79694\nsynclink.ko_merged.c:22124
(*) .irq_requested#79688\nsynclink.ko_merged.c:22124
(*) .last_mem_alloc#79702\nsynclink.ko_merged.c:22124
(*) .lcr_base#79701\nsynclink.ko_merged.c:22124
(*) .lcr_mem_requested#79700\nsynclink.ko_merged.c:22124
(*) .loopback_bits#79704\nsynclink.ko_merged.c:22124
(*) .loopmode_insert_requested#79559\nsynclink.ko_merged.c:22124 (non-lin)
(*) .loopmode_send_done_requested#79705\nsynclink.ko_merged.c:22124
(*) .mbre_bit#79709\nsynclink.ko_merged.c:22124
(*) .memory_base#79708\nsynclink.ko_merged.c:22124
(*) .misc_ctrl_value#79707\nsynclink.ko_merged.c:22124
(*) .params#79722\nsynclink.ko_merged.c:22124
(*) .pending_bh#79721\nsynclink.ko_merged.c:22124
(*) .put_tx_holding_index#79718\nsynclink.ko_merged.c:22124
(*) .read_status_mask#79585\nsynclink.ko_merged.c:22124
(*) .ri_chkcount#79583\nsynclink.ko_merged.c:22124
(*) .rx_buffer_count#79725\nsynclink.ko_merged.c:22124
(*) .rx_buffer_list#79726\nsynclink.ko_merged.c:22124
(*) .rx_enabled#79723\nsynclink.ko_merged.c:22124
(*) .rx_overflow#79724\nsynclink.ko_merged.c:22124
(*) .rx_rcc_underrun#79728\nsynclink.ko_merged.c:22124
(*) .serial_signals#79731\nsynclink.ko_merged.c:22124
(*) .shared_mem_requested#79730\nsynclink.ko_merged.c:22124
(*) .start_tx_dma_buffer#79732\nsynclink.ko_merged.c:22124
(*) .tcsr_value#79740\nsynclink.ko_merged.c:22124
(*) .timeout#79599\nsynclink.ko_merged.c:22124
(*) .tty#79744\nsynclink.ko_merged.c:22124
(*) .tx_active#79741\nsynclink.ko_merged.c:22124
(*) .tx_buffer_count#79735\nsynclink.ko_merged.c:22124
(*) .tx_buffer_list#79739\nsynclink.ko_merged.c:22124
(*) .tx_dma_buffers_used#79738\nsynclink.ko_merged.c:22124
(*) .tx_enabled#79742\nsynclink.ko_merged.c:22124
(*) .tx_holding_count#79737\nsynclink.ko_merged.c:22124
(*) .usc_idle_mode#79746\nsynclink.ko_merged.c:22124
(*) .x_char#79749\nsynclink.ko_merged.c:22124
(*) .xmit_buf#79747\nsynclink.ko_merged.c:22124
(*) .xmit_cnt#79748\nsynclink.ko_merged.c:22124
(*) .xmit_head#79751\nsynclink.ko_merged.c:22124
(*) .xmit_tail#79750\nsynclink.ko_merged.c:22124

Instances of mgsl_struct are all created on line 22124, in
mgsl_allocate_device, which is called in mgsl_enum_isa_devices, which
then calls mgsl_add_device to link the struct into the global list
stored in mgsl_device_list.  The function mgsl_enum_isa_devices is
called as part of the initialization process, in synclink_init.

When mgsl_open is called, it iterates through the list of devices and
picks the correct one out, and then stores it in tty->driver_data,
from which it's accessed by the other functions.

We could prevent this list from being shared by either adding a
#pragma saying that this structure should be thread-local.

Hack:  Modify mgsl_open to call mgsl_allocate_device() directly to
allocate a new device, rather than returning one from the list.  This
changes the warning count up to 72 (!).  Next attempt:  don't call
mgsl_read_proc, since that also goes through the info list again.

(*) .closing#79762\nsynclink.ko_merged.c:24655 (THREAD-LOCAL)
(*) .driver_data#79765\nsynclink.ko_merged.c:24655
(*) .flags#79757\nsynclink.ko_merged.c:24655
(*) .hw_stopped#79759\nsynclink.ko_merged.c:24655
(*) .low_latency#79753\nsynclink.ko_merged.c:24655

False positives.  This is the tty struct, which is thread-local to
each driver.  Hence none of its fields are shared. Our analysis
doesn't catch this because the tty itself is stored in the info,
hence it becomes shared.
POLYVIOS: 

I'm not sure this is thread local.  This is s

(*) .data_bits#79487\nsynclink.ko_merged.c:23963
(*) .data_bits#79500\nsynclink.ko_merged.c:18127
(*) .data_bits#79513\nsynclink.ko_merged.c:18127
(*) .data_bits#79820\nsynclink.ko_merged.c:19909
(*) .data_rate#79486\nsynclink.ko_merged.c:23963
(*) .data_rate#79499\nsynclink.ko_merged.c:18127
(*) .data_rate#79512\nsynclink.ko_merged.c:18127
(*) .data_rate#79821\nsynclink.ko_merged.c:19909 
(*) .mode#79478\nsynclink.ko_merged.c:23963
(*) .mode#79491\nsynclink.ko_merged.c:18127
(*) .mode#79504\nsynclink.ko_merged.c:18127
(*) .mode#79812\nsynclink.ko_merged.c:19909
(*) .parity#79483\nsynclink.ko_merged.c:23963
(*) .parity#79496\nsynclink.ko_merged.c:18127
(*) .parity#79509\nsynclink.ko_merged.c:18127
(*) .parity#79817\nsynclink.ko_merged.c:19909
(*) .stop_bits#79476\nsynclink.ko_merged.c:23963
(*) .stop_bits#79489\nsynclink.ko_merged.c:18127
(*) .stop_bits#79502\nsynclink.ko_merged.c:18127
(*) .stop_bits#79810\nsynclink.ko_merged.c:19909

False positive due to copying locations of fields when copying struct
by value.

(*) alloc#13999\nsynclink.ko_merged.c:21699

Believe this is thread-local data stored in mgsl_struct.

(*) alloc#14227\nsynclink.ko_merged.c:21767

False positive.  Thread local in a complicated way.  This memory is
a buffer for DMA, allocated by the following call chain:

(mgsl_open ->
 startup ->
 mgsl_claim_resources ->
 mgsl_allocate_dma_buffers ->
 allocated in mgsl_alloc_frame_memory)

A pointer to this memory is getting stored in mgsl_struct, hence it
appears shared even though it's not.  So this is the same issue as
mgsl_struct above.

(*) alloc#14339\nsynclink.ko_merged.c:21813

No info; will assume it's thread local

(*) alloc#14491\nsynclink.ko_merged.c:21842 (non-lin)

This seems to be the same issue, again.  This memory is stored into an
mgsl_struct, and  hence is appearing shared.

##

(*) .base#86119\nsynclink.ko_merged.c:22124

This warning appeared in an earlier test run but is gone now.
However, this is baffling because there's no .base field of that
struct.  Hence this is probably due to some weird cut-and-paste error
I made while hacking up the main, though that seems strange.

(*) &tmp_params#22481\nsynclink.ko_merged.c:23963
(*) &tmp_params#8042\nsynclink.ko_merged.c:19909

False positives.  Like &default_params above, this looks like
conservatism due to conflation at __constant_memcpy.

(Eliminated by adding __constant_memcpy to list, but this is unsound
right now.)

(*) &default_params#1973\nsynclink.ko_merged.c:18127 (MEMCPY)

False positive.  This data is copied over to info->params on line
22162, and somehow the two are become aliased, probably from
conflation, since there is code for __constant_memcpy.  Adding
__constant_memcpy to the list of functions and improving the modeling
of memcpy would remove this.

(Eliminated by adding __constant_memcpy to list, but this is unsound
right now.)

WAVELAN
=======

Warnings
24

(*) &dummydev#10936\nwavelan.ko_merged.c:20030

Ignore this race---it's due to our own structuring of the main driver.

(*) &wavelan_list#2206\nwavelan.ko_merged.c:17060

False positive.  wavelan_list is accessed within threads, and it's
also changed as the list is destroyed in cleanup_module.  We don't
know that cleanup_module is only called after all the threads have
finished, so we see this as a race.

There's something strange going on here with the guarded-bys.  I'm not
seeing the individual writes in the threads.  ?

(*) .base_addr#33034\nwavelan.ko_merged.c:20046
(*) .get_stats#33016\nwavelan.ko_merged.c:20046
(*) .hard_start_xmit#33020\nwavelan.ko_merged.c:20046
(*) .if_port#33023\nwavelan.ko_merged.c:20046
(*) .irq#33022\nwavelan.ko_merged.c:20046
(*) .mem_end#33028\nwavelan.ko_merged.c:20046
(*) .mem_start#33027\nwavelan.ko_merged.c:20046
(*) .mtu#33029\nwavelan.ko_merged.c:20046
(*) .open#33032\nwavelan.ko_merged.c:20046
(*) .priv#33033\nwavelan.ko_merged.c:20046
(*) .set_multicast_list#33038\nwavelan.ko_merged.c:20046
(*) .stop#33037\nwavelan.ko_merged.c:20046
(*) .tx_timeout#33041\nwavelan.ko_merged.c:20046
(*) .watchdog_timeo#33017\nwavelan.ko_merged.c:20046
(*) .wireless_data#33019\nwavelan.ko_merged.c:20046
(*) .wireless_handlers#33018\nwavelan.ko_merged.c:20046

False positives due to some kind of aliasing.  Not sure what's going
on here.  I extracted this down to a small example, only to find that
running with --dont-compact-structs eliminated the race.  However,
running with --dont-compact-structs on the whole file still produces
the same number of races.

(*) .dev#33014\nwavelan.ko_merged.c:20057 (FANCIER UNIQUENESS)

False positive.  These are writes to a thread-local field of a
thread-local, freshly allocated struct.

There also appears to be some conservatism in the alias analysis;
there are actually two places where a struct sk_buff is allocated, and
writes to them are being reported as writes to the same rho.

(*) .flags#33015\nwavelan.ko_merged.c:20046

Race? This is the same conflated struct as above.  The dev->flags
field is written within wavelan_set_multicast_list.  It might be a
race---but this function isn't actually called from anywhere.

(*) .last_rx#33024\nwavelan.ko_merged.c:20046
(*) .trans_start#33040\nwavelan.ko_merged.c:20046

Races?  

The first appears to be a counter, and is written to with no locks
held, in wv_packet_read with no locks held.  However, it's called by
wavelan_interrupt, in which case this might be safe?

The second is written in wv_packet_write with no locks held.  This
doesn't seem to be in an interrupt context.

(*) .next_sched#33030\nwavelan.ko_merged.c:20046 (EXISTS?)
(*) .state#33036\nwavelan.ko_merged.c:20046

These fields of dev is accessed only if lp->spinlock is held, where it's
dev->lp->spinlock.

FRESHCLAM
=========

Old 1 warning:

Warning: Possible data race: &initialised#112649\nfreshclam_comb.c:27671 is not protected!
references:
  guard@freshclam_comb.c:27699
  rho: &initialised#112649\nfreshclam_comb.c:27671
  acq:
  through:

  guard@freshclam_comb.c:27693
  rho: &initialised#112649\nfreshclam_comb.c:27671
  acq: Cl#112653\nfreshclam_comb.c:27672
       l#112652\nfreshclam_comb.c:27672
       l#112650\nfreshclam_comb.c:27672
  through:

Polyvios:
the only notes i found on freshclam_comb.c stated that all of the fields of 
cl_cvd allocated in cl_cvdparse() were false positives that went away with 
existentials.  i'll look into the code to try and find out why.

Traced on 0.88 versions

In freshclam:

cl_cvdparse
<- remote_cvdhead
   <- downloaddb
      <- downloadmanager
         <- download
            <- freshclam
               <- main
<- cl_cvdhead
   <- freshdbdir
      <- print_version
         <- writepid
            <- freshclam
   <- print_version [see above]
   <- downloaddb [see above]
<- cli_cvdverify
   <- cl_cvdverify
      <- downloaddb [see above]
   <- cli_cvdload
      <- cl_loaddb
         <- cl_loaddbdir
            <- cli_cvdload [see above]

In clamd:

cl_cvdparse
<- cl_cvdhead
   <- freshdbdir
      <- print_version
         <- clamd
            <- main
   <- print_version [see above]
   <- command
      <- scanner_thread
         <- ``forked'' in acceptloop_th by call to thrmgr_new
            <- tcpserver
               <- clamd
<- cli_cvdverify
   <- cl_cvdverify
   <- cli_cvdload
      <- cl_loaddb
         <- cl_loaddbdir
            <- clamd [see above]
            <- reload_db
               <- acceptloop_th [see above]
            <- cli_cvdload [see above]

ESP-2.5.62
==========

(*) &dma_buffer#3193\nesp-2.5.62.c:7118

RACE!  Set in startup(), called in esp_open(), and no locks are held when reading

(*) &dma_bytes#3194\nesp-2.5.62.c:7119
(*) &tmp_buf#3241\nesp-2.5.62.c:7132
(*) .IER#34934\nesp-2.5.62.c:8822
(*) .IER#34970\nesp-2.5.62.c:8765
(*) .MCR#34940\nesp-2.5.62.c:8822
(*) .MCR#34976\nesp-2.5.62.c:8765
(*) .alt_speed#34911\nesp-2.5.62.c:8894
(*) .blocked_open#34922\nesp-2.5.62.c:8822
(*) .blocked_open#34958\nesp-2.5.62.c:8765
(*) .closing#34914\nesp-2.5.62.c:8894
(*) .count#34930\nesp-2.5.62.c:8822
(*) .count#34966\nesp-2.5.62.c:8765
(*) .driver_data#34917\nesp-2.5.62.c:8894
(*) .flags#34909\nesp-2.5.62.c:8894
(*) .flags#34933\nesp-2.5.62.c:8822
(*) .flags#34969\nesp-2.5.62.c:8765
(*) .ignore_status_mask#34936\nesp-2.5.62.c:8822
(*) .ignore_status_mask#34972\nesp-2.5.62.c:8765
(*) .pgrp#34946\nesp-2.5.62.c:8822
(*) .pgrp#34982\nesp-2.5.62.c:8765
(*) .read_status_mask#34947\nesp-2.5.62.c:8822
(*) .read_status_mask#34983\nesp-2.5.62.c:8765
(*) .session#34949\nesp-2.5.62.c:8822
(*) .session#34985\nesp-2.5.62.c:8765
(*) .stat_flags#34948\nesp-2.5.62.c:8822
(*) .stat_flags#34984\nesp-2.5.62.c:8765
(*) .timeout#34950\nesp-2.5.62.c:8822
(*) .timeout#34986\nesp-2.5.62.c:8765
(*) .tty#34953\nesp-2.5.62.c:8822
(*) .tty#34989\nesp-2.5.62.c:8765
(*) .unsafe#35062\nesp-2.5.62.c:4437
(*) .unsafe#35080\nesp-2.5.62.c:4437
(*) .xmit_buf#34918\nesp-2.5.62.c:8822
(*) .xmit_buf#34954\nesp-2.5.62.c:8765
(*) .xmit_cnt#34921\nesp-2.5.62.c:8822
(*) .xmit_cnt#34957\nesp-2.5.62.c:8765
(*) .xmit_head#34920\nesp-2.5.62.c:8822
(*) .xmit_head#34956\nesp-2.5.62.c:8765
(*) .xmit_tail#34919\nesp-2.5.62.c:8822
(*) .xmit_tail#34955\nesp-2.5.62.c:8765

SYNCLINK -- latest warnings
===========================

(*) &tmp_buf#2946\nsynclink.ko_merged.c:18463

RACE!  This is a static global variable re-used across all instances.
In fact, there's a semaphore declared right after it in the source code, along
with a comment on why we need it to protect that variable, but the buf is
never protected.

(*) .bh_requested#79503\nsynclink.ko_merged.c:22124
(*) .bh_running#79504\nsynclink.ko_merged.c:22124
(*) .blocked_open#79502\nsynclink.ko_merged.c:22124

I don't understand why these are shared.  We report only guards created
by reads.  There are write accesses but they're not in reachable code, only in
bh_handler with we never call in main().

(*) .buffer_list#79499\nsynclink.ko_merged.c:22124

Could be a race, i'm not sure.  This is read and freed in _init and _exit,
as well as in mgsl_open.  It's not protected, the read and write within open
(through the reported inst-path) could be a race if open can be called by
many threads.

(*) .buffer_list_phys#79500\nsynclink.ko_merged.c:22124

This is set right after the kmalloc(), so it's not shared then.
POSSIBLE LOCKSMITH BUG: we don't report the second dereference
of that field within that same function.

(*) .closing#79603\nsynclink.ko_merged.c:24655
(*) .driver_data#79606\nsynclink.ko_merged.c:24655
(*) .flags#79598\nsynclink.ko_merged.c:24655
(*) .hw_stopped#79600\nsynclink.ko_merged.c:24655
(*) .low_latency#79594\nsynclink.ko_merged.c:24655

These depend or our model of main().  These are locations passed into the
driver functions by our main() and refer to global structs (that we have added).

(*) .cmr_value#79507\nsynclink.ko_merged.c:22124
(*) .count#79509\nsynclink.ko_merged.c:22124
(*) .cts_chkcount#79508\nsynclink.ko_merged.c:22124
(*) .current_rx_buffer#79506\nsynclink.ko_merged.c:22124
(*) .current_tx_buffer#79505\nsynclink.ko_merged.c:22124
(*) .dcd_chkcount#79515\nsynclink.ko_merged.c:22124
(*) .dma_requested#79513\nsynclink.ko_merged.c:22124
(*) .drop_rts_on_tx_done#79514\nsynclink.ko_merged.c:22124 (non-lin)
(*) .dsr_chkcount#79516\nsynclink.ko_merged.c:22124
(*) .flags#79522\nsynclink.ko_merged.c:22124
(*) .get_tx_holding_index#79523\nsynclink.ko_merged.c:22124
(*) .idle_mode#79539\nsynclink.ko_merged.c:22124
(*) .ignore_status_mask#79536\nsynclink.ko_merged.c:22124
(*) .init_error#79537\nsynclink.ko_merged.c:22124
(*) .intermediate_rxbuffer#79531\nsynclink.ko_merged.c:22124
(*) .io_addr_requested#79530\nsynclink.ko_merged.c:22124
(*) .irq_occurred#79535\nsynclink.ko_merged.c:22124
(*) .irq_requested#79529\nsynclink.ko_merged.c:22124
(*) .last_mem_alloc#79543\nsynclink.ko_merged.c:22124
(*) .lcr_base#79542\nsynclink.ko_merged.c:22124
(*) .lcr_mem_requested#79541\nsynclink.ko_merged.c:22124
(*) .loopback_bits#79545\nsynclink.ko_merged.c:22124
(*) .loopmode_insert_requested#79544\nsynclink.ko_merged.c:22124 (non-lin)
(*) .loopmode_send_done_requested#79546\nsynclink.ko_merged.c:22124 (non-lin)
(*) .mbre_bit#79550\nsynclink.ko_merged.c:22124
(*) .memory_base#79549\nsynclink.ko_merged.c:22124
(*) .misc_ctrl_value#79548\nsynclink.ko_merged.c:22124
(*) .params#79563\nsynclink.ko_merged.c:22124
(*) .pending_bh#79562\nsynclink.ko_merged.c:22124
(*) .put_tx_holding_index#79559\nsynclink.ko_merged.c:22124
(*) .read_status_mask#79570\nsynclink.ko_merged.c:22124
(*) .ri_chkcount#79568\nsynclink.ko_merged.c:22124
(*) .rx_buffer_count#79564\nsynclink.ko_merged.c:22124
(*) .rx_buffer_list#79565\nsynclink.ko_merged.c:22124
(*) .rx_enabled#79567\nsynclink.ko_merged.c:22124
(*) .rx_overflow#79566\nsynclink.ko_merged.c:22124
(*) .rx_rcc_underrun#79569\nsynclink.ko_merged.c:22124
(*) .serial_signals#79572\nsynclink.ko_merged.c:22124
(*) .shared_mem_requested#79571\nsynclink.ko_merged.c:22124
(*) .start_tx_dma_buffer#79573\nsynclink.ko_merged.c:22124
(*) .tcsr_value#79581\nsynclink.ko_merged.c:22124
(*) .timeout#79584\nsynclink.ko_merged.c:22124
(*) .tty#79585\nsynclink.ko_merged.c:22124
(*) .tx_active#79579\nsynclink.ko_merged.c:22124
(*) .tx_buffer_count#79576\nsynclink.ko_merged.c:22124
(*) .tx_buffer_list#79580\nsynclink.ko_merged.c:22124
(*) .tx_dma_buffers_used#79583\nsynclink.ko_merged.c:22124
(*) .tx_enabled#79582\nsynclink.ko_merged.c:22124
(*) .tx_holding_count#79578\nsynclink.ko_merged.c:22124
(*) .usc_idle_mode#79587\nsynclink.ko_merged.c:22124
(*) .x_char#79590\nsynclink.ko_merged.c:22124
(*) .xmit_buf#79588\nsynclink.ko_merged.c:22124
(*) .xmit_cnt#79589\nsynclink.ko_merged.c:22124
(*) .xmit_head#79592\nsynclink.ko_merged.c:22124
(*) .xmit_tail#79591\nsynclink.ko_merged.c:22124
(*) alloc#14187\nsynclink.ko_merged.c:21767
(*) alloc#14448\nsynclink.ko_merged.c:21842

Above here is in prior synclink discussion---note that we find more
shared fields.

(1) .data_bits#79472\nsynclink.ko_merged.c:23963 (MEMCPY modeling)
(2) .data_bits#79485\nsynclink.ko_merged.c:18127
(3) .data_bits#79498\nsynclink.ko_merged.c:18127
(1) .data_bits#79810\nsynclink.ko_merged.c:19909
(1) .data_rate#79471\nsynclink.ko_merged.c:23963
(2) .data_rate#79484\nsynclink.ko_merged.c:18127
(3) .data_rate#79497\nsynclink.ko_merged.c:18127
(1) .data_rate#79811\nsynclink.ko_merged.c:19909
(1) .mode#79463\nsynclink.ko_merged.c:23963
(2) .mode#79476\nsynclink.ko_merged.c:18127
(3) .mode#79489\nsynclink.ko_merged.c:18127
(1) .mode#79802\nsynclink.ko_merged.c:19909
(1) .parity#79468\nsynclink.ko_merged.c:23963
(2) .parity#79481\nsynclink.ko_merged.c:18127
(3) .parity#79494\nsynclink.ko_merged.c:18127
(1) .parity#79807\nsynclink.ko_merged.c:19909
(1) .stop_bits#79461\nsynclink.ko_merged.c:23963
(2) .stop_bits#79487\nsynclink.ko_merged.c:18127
(3) .stop_bits#79474\nsynclink.ko_merged.c:18127
(1) .stop_bits#79800\nsynclink.ko_merged.c:19909

All of these appear to be races, but *not* on the reported locations.
They're actually races on the info field---to which all these things
are copied.  So we *should* be getting races on the info field, but
*not* on these locations.

In detail:
(1) is caused by imprecision due to memcpy.  A shared struct is
copied to a  local variable causing their types to be unified.
Single-direction memcpy of structs will fix this.

(2) and (3) are similar except the *source* is a global constant variable,
copied to something shared.
NOTE:
These two constant rhos are aliased.  We allocate one for the global struct
variable (not a pointer, concrete struct), and another one for the
initializer, and the two are aliased.  We should report only one, this is
really the same location, and should count as one false positive.

The reason that only the fields (and not the struct itself) are reported
as races, is that it's never allocated.  I added a call to
mgsl_allocate_device() in main(), i'll update the results after re-running.

POSSIBLE LOCKSMITH IMPROVEMENT: we could reduce the # of false positives
here by 1) grouping races on struct fields & the struct together, and
2) handling memcpy as directed assignment instead of unification.


(*) alloc#13999\nsynclink.ko_merged.c:21699

Race?

This info->buffer_list, which is an alias of info->tx_buffer_list.
This region appears to be written in mgsl_load_tx_dma_buffer, which is
called by mgsl_flush_chars.

(*) alloc#14339\nsynclink.ko_merged.c:21813

Race?

This is accessed without a lock held in mgsl_get_raw_rx_frame, called
from mgsl_bh_receive without a lock held.

EXTRA WARNINGS:
These warnings were added when I modified main() to allocate a mgsl_struct

&mgsl_bh_handler#3265\nsynclink.ko_merged.c:18569
&tty#24031\nsynclink.ko_merged.c:24655
.close_delay#61928\nsynclink.ko_merged.c:22124
.close_wait#61930\nsynclink.ko_merged.c:22124


EQL
===

&dummydev#3279\neql.ko_merged.c:16480 is not protected!

False positive.  This one is created in our code.

(*) .dev#8918\neql.ko_merged.c:16508

False positive due to losing a lock that's stored in a struct.  We
don't find any concrete locks, even though the accesses do seem to be
guarded by a lock in a struct.  A use of EXISTS?

(*) .flags#8923\neql.ko_merged.c:16496

False positive due to conflation of rhos (.flags is conlfated with
lots of other stuff)

(*) .list#9034\neql.ko_merged.c:16014

Lock stored in a struct is used to guard access, and we're losing
that, plus it's getting conflated with lots of other stuff

(*) .priority#8917\neql.ko_merged.c:16508 (non-lin)

this is only accessed in xmit() paths, so since we hold a lock around xmit,
it's found to be protected.  The lock is non-linear because the register
function that creates it is called from two contexts, both flowing to
dummydev, I think.

-- no, it's not called from two contexts.  Unclear why we're missing
this.

alloc#3332\neql.ko_merged.c:16496 is not protected!

false positive.  it's passed into list_empty that checks the list (read only),
that's why we don't infer it's guarded by the nonlinear lock around
xmit().  Conflation is really killing us, though.

SLIP
====


(*) .dev#25313\nslip.ko_merged.c:22643

Seems to be the same false positive on .dev in PLIP.

SIS900
======

(*) &dummydev#10721\nsis900.ko_merged.c:20341

The usual false positive due to our driver

(*) .dev#74591\nsis900.ko_merged.c:20368

The usual false positive from dev.  There's an allocation function
whose result we don't know is fresh, so I think we believe it's
shared.

(*) .last_rx#74599\nsis900.ko_merged.c:20357

False positive.  This would be a race, but interrupts for the device
are disabled, so I assume we can never be in this code twice---Iulian
says yes, that's the case.

(*) .len#74584\nsis900.ko_merged.c:20368

Unclear why we're getting this warning.  This field seems to only be
written by code that's not executed?

(*) .next#74586\nsis900.ko_merged.c:20368
(*) .tail#74585\nsis900.ko_merged.c:20368

False positive.  There's a lock in a data structure that guards it,
but we seem to be missing the fact that it's held on sis900_interrupt
-> sis900_finish_xmit -> dev_kfree_skb_irq.  For the second, it's
sis900_interrupt -> sis900_rx -> skb_put

(*) .next#74907\nsis900.ko_merged.c:18307

No information is given about this race, so I'll assume it's a false
positive.

(*) .next_sched#74602\nsis900.ko_merged.c:20357

Seems to be relying on cli() call to make this safe.

(*) .phy_addr#74904\nsis900.ko_merged.c:18307
(*) .phy_id0#74906\nsis900.ko_merged.c:18307
(*) .phy_id1#74905\nsis900.ko_merged.c:18307
(*) .phy_types#74902\nsis900.ko_merged.c:18307
(*) .status#74903\nsis900.ko_merged.c:18307

False positives.  All of these fields are set at initialization time
and then only read.  However, it appears that our uniqueness analysis
is getting killed because there's an error path that doesn't return on
which the variable mii_phy set to the freshly allocated struct is
instead used to traverse a list and free its elements.  (Have not
verified that's exactly the issue.)

(*) .state#74610\nsis900.ko_merged.c:20357

Assume this is a false positive, since manipulated by assembly code.

(*) .trans_start#74616\nsis900.ko_merged.c:20357

RACE!  This is a counter set with no locks held, in fact immediately
after one lock is released.

3C501
=====

(*) &dummydev#4734\n3c501.ko_merged.c:17357

Usual fp due to our main

(*) &el_debug#1857\n3c501.ko_merged.c:16394

RACE!  Set in module_activity -> netdev_set_msglevel.  Read in el_open
without a lock.

(*) &io#1858\n3c501.ko_merged.c:16395
(*) &irq#1859\n3c501.ko_merged.c:16396
(*) &mem_start#1860\n3c501.ko_merged.c:16397

False positives.  Seem to only be set in el1_probe1, which is only
called during initialization.  Not sure why we're reporting these.

(*) .base_addr#21713\n3c501.ko_merged.c:17373
(*) .ethtool_ops#21720\n3c501.ko_merged.c:17373
(*) .get_stats#21700\n3c501.ko_merged.c:17373
(*) .hard_start_xmit#21702\n3c501.ko_merged.c:17373
(*) .irq#21704\n3c501.ko_merged.c:17373
(*) .lock#21695\n3c501.ko_merged.c:17374
(*) .open#21710\n3c501.ko_merged.c:17373
(*) .set_multicast_list#21714\n3c501.ko_merged.c:17373
(*) .stop#21715\n3c501.ko_merged.c:17373
(*) .tx_timeout#21719\n3c501.ko_merged.c:17373
(*) .watchdog_timeo#21701\n3c501.ko_merged.c:17373

False positive.  Only set in el1_probe1, only called during init.

(*) .collisions#21693\n3c501.ko_merged.c:17374 (non-lin)
(*) .tx_pkt_start#21697\n3c501.ko_merged.c:17374 (non-lin)

False positive.  Protected by a lock in a data structure that we think
is non-linear.

(*) .dev#21692\n3c501.ko_merged.c:17384

False positive.  We lose the uniqueness of a freshly allocated sk_buff
because it's passed to an initialization function.

(*) .last_rx#21705\n3c501.ko_merged.c:17373

RACE!  Set in el_receive with no locks held

(*) .loading#21694\n3c501.ko_merged.c:17374
(*) .trans_start#21718\n3c501.ko_merged.c:17373

False positive.  Guarded by lock lp->lock stored in struct, but we
seem to be missing the lock aquire.

(*) .next_sched#21708\n3c501.ko_merged.c:17373

False positive.  Seems to assume protection by cli()?  Or maybe some
invariant of the state field?

(*) .state#21717\n3c501.ko_merged.c:17373

False positive.  Munged by inline assembly, so probably ok.

(*) .txing#21698\n3c501.ko_merged.c:17374

RACE!  Set in el_open without a lock held (lp->lock is in fact just
released above it).

(*) alloc#4779\n3c501.ko_merged.c:17373
(*) alloc#4784\n3c501.ko_merged.c:17374

Seem to be false positives due to aliasing, but didn't investigate too
closely because they're aliased with tons of other stuff.

HP100
=====


&gendev#11900\nhp100.ko_merged.c:20361

False positive.  Created by main().

.base_addr#26959\nhp100.ko_merged.c:20294

False positive, due to our main() model.  The unprotected access happens in
the interrupt handler, which can't be interrupted itself.
Also there are unprotected accesses during initialization, that cause the
guard-set to be empty.

.counter#26944\nhp100.ko_merged.c:20305

False positive.  It is only accessed in the function atomic_dec_and_test,
which ..is atomic.  We could model that by adding a global lock protecting
the access in this function.

.dev#26943\nhp100.ko_merged.c:20305
.dma#26866\nhp100.ko_merged.c:20294
.driver_data#26873\nhp100.ko_merged.c:20361
.tail#26843\nhp100.ko_merged.c:20305

False positives.  All these seem to be conflated through an int*.
However, there is a lock acquired around the offending accesses but
we can't track that lock and add it to the guard.  It seems there's a
problem with casting to and from dev->priv (it's done using an offset on
the pointer).


.irq#26854\nhp100.ko_merged.c:20294
.mem_end#26856\nhp100.ko_merged.c:20294
.mem_start#26857\nhp100.ko_merged.c:20294
.open#26860\nhp100.ko_merged.c:20294
.get_stats#26851\nhp100.ko_merged.c:20294
.hard_start_xmit#26852\nhp100.ko_merged.c:20294
.set_multicast_list#26867\nhp100.ko_merged.c:20294
.stop#26868\nhp100.ko_merged.c:20294

False positives.  All reported accesses are either reads, or protected.
All offending accesses happen before the first fork during init.


.last_rx#26855\nhp100.ko_merged.c:20294
.protocol#26846\nhp100.ko_merged.c:20305

These are races given our main().  However, when hp100_rx is called from
inside hp100_interrupt, a spin lock is acquired, so maybe it is the
caller's responsibility to protect calls to the rx function.


.len#26842\nhp100.ko_merged.c:20305
.next#26844\nhp100.ko_merged.c:20305

Race for our main() but not really:
offending dereferences in hp100_hard_xmit called from within main().
other calls of the hard_xmit function are protected, so this is probably
caused by our main() again.


.state#26869\nhp100.ko_merged.c:20294

Empty guardedby.  Accessed by an assembly block that sets a bit (atomically).


.trans_start#26870\nhp100.ko_merged.c:20294

Empty guardedby.  Looks like a race, unless calls of hp100_open should be
locked by the caller.

alloc#11639\nhp100.ko_merged.c:20294
alloc#11644\nhp100.ko_merged.c:20295

False positives.
Offending access is in hp100_rx again, which should probably by called with
lock dev->priv->lock acquired.  Race for this main(), but most probably a
false positive.  These are conflated, too, because they're dereferenced using
readl() which uses int* to store the pointer.


SUNDANCE
========

.dev#59553\nsundance.ko_merged.c:19897

False positive.  Uniqueness should handle this but somehow doesn't.


.if_port#59632\nsundance.ko_merged.c:19886

Race for our main() but not really.  netdev_open should be protected by
a global lock.


.mtu#59634\nsundance.ko_merged.c:19886

False positive, location is not shared, it's never written.
We shouldn't have marked it as shared.


.next#59548\nsundance.ko_merged.c:19897

Should have been protected.  Access is in dev_kfree_skb_irq which is called
from tx_timeout with a lock acquired.

.next_sched#59637\nsundance.ko_merged.c:19886

False positive.  Uses a test_and_clear_bit operation to synchronize, which we
don't handle.  Should(?) behave exactly like trylock.



.state#59645\nsundance.ko_merged.c:19886

False positive.
This is the bit-field that is used as a lock to protect the location above.
the test-and-set is done in inline assembly, so we assume it's dereferenced
without synchronization.


.trans_start#59652\nsundance.ko_merged.c:19886

False positive: it should be protected by dummydev->lock_xmit.
dereferenced within start_tx (which is protected by dummydev->lock_xmit).
The lock is in the function effects for some strange reason, so it's not
on the "split" set.
